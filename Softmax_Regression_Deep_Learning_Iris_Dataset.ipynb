{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fae30032570>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use train_test_split to split data into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, x_val, y, y_val = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4), (100,), (50, 4), (50,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x.reshape(-1, x.shape[1]).astype('float32')\n",
    "y_train = y\n",
    "\n",
    "x_val = x_val.reshape(-1, x_val.shape[1]).astype('float32')\n",
    "y_val = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define validation data as a Pytorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = torch.from_numpy(x_val)\n",
    "y_val = torch.from_numpy(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put Data through DataLoader, so we can use batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Data(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x=torch.from_numpy(x_train)\n",
    "        self.y=torch.from_numpy(y_train)\n",
    "        self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):      \n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader=DataLoader(dataset=data_set,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.6000, 3.0000, 6.6000, 2.1000],\n",
       "        [5.6000, 3.0000, 4.5000, 1.5000],\n",
       "        [5.1000, 3.5000, 1.4000, 0.2000],\n",
       "        [7.7000, 2.8000, 6.7000, 2.0000],\n",
       "        [5.8000, 2.7000, 4.1000, 1.0000],\n",
       "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
       "        [5.0000, 3.5000, 1.3000, 0.3000],\n",
       "        [5.1000, 3.8000, 1.9000, 0.4000],\n",
       "        [5.0000, 2.0000, 3.5000, 1.0000]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.x[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 0, 2, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.y[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 4]), torch.Size([100]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.x.shape, data_set.y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model and train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build softmax Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,D_in,H,D_out):\n",
    "        super(Net,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H)\n",
    "        self.linear2=nn.Linear(H,D_out)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=torch.sigmoid(self.linear1(x))  \n",
    "        x=self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim=4     # how many Variables are in the dataset\n",
    "hidden_dim = 25 # hidden layers\n",
    "output_dim=3    # number of classes\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model=Net(input_dim,hidden_dim,output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the size of the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: torch.Size([25, 4])\n",
      "b torch.Size([25])\n"
     ]
    }
   ],
   "source": [
    "print('W:',list(model.parameters())[0].size())\n",
    "print('b',list(model.parameters())[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.1\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=1000\n",
    "loss_list=[]\n",
    "\n",
    "#n_epochs\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "      \n",
    "\n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        z=model(x)\n",
    "        # calculate loss, da Cross Entropy benutzt wird muss ich in den loss Klassen vorhersagen, \n",
    "        # also Wahrscheinlichkeit pro Klasse. Das mach torch.max(y,1)[1])\n",
    "        loss=criterion(z,y)\n",
    "        # calculate gradients of parameters \n",
    "        loss.backward()\n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.data)\n",
    "        \n",
    "        \n",
    "        #print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  9.3748,   4.2373, -13.0650],\n",
       "        [ -5.3994,   1.9242,   3.5881],\n",
       "        [ -1.6497,   3.4716,  -1.5646],\n",
       "        [ -5.3590,   1.9075,   3.5724],\n",
       "        [  1.0837,   4.4060,  -5.1889],\n",
       "        [ -2.1853,   3.1301,  -0.6984],\n",
       "        [ -2.4463,   3.2549,  -0.5641],\n",
       "        [  7.8511,   4.3348, -11.7414],\n",
       "        [ -1.5189,   3.7685,  -2.0043],\n",
       "        [ -3.1103,   2.9239,   0.4084]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row represents a row from the original dataset. Each column represents a class. The first column represents the class 0, the second column class 1 and the third column class 2. The highest value for each row represents which class the model would put each row. For instance, the highest value in the first row is 9.3748, hence the predicted class is 0.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check model on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=model(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.0738, 9.2892, 7.5300, 2.9072, 3.2767, 9.0327, 3.9651, 3.4732, 2.4689,\n",
       "         3.8023, 3.0332, 8.8700, 9.4850, 8.8601, 9.3904, 3.0966, 6.2266, 3.6219,\n",
       "         2.8405, 6.1747, 8.6625, 2.8811, 8.7867, 5.9667, 3.6716, 4.4869, 5.8407,\n",
       "         6.0122, 8.6818, 8.5801, 9.6922, 9.8235, 3.9622, 8.9117, 9.0107, 4.3871,\n",
       "         3.5250, 9.2316, 9.3840, 9.7249, 5.1719, 3.1824, 3.4399, 9.6400, 9.4289,\n",
       "         3.8427, 2.6601, 4.3333, 3.8105, 5.8017]),\n",
       " tensor([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2,\n",
       "         2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2,\n",
       "         1, 2]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat=torch.max(z.data,1)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2,\n",
       "        2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2,\n",
       "        1, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
